{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    df = pd.read_csv(path, skiprows=72, header=None, sep=r'\\s+', index_col=0)\n",
    "    df.columns = [f'A{i}' for i in range(1, 16)] + ['B']\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df.iloc[:, :-1], df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoader(X_train,y_train,batch_size=16):\n",
    "    idx = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    X_train,y_train = X_train[idx],y_train[idx]\n",
    "    for i in range(0,X_train.shape[0],batch_size):\n",
    "        start,end = i,min(X_train.shape[0],i+batch_size)\n",
    "        yield X_train[start:end],y_train[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_add_ones(X):\n",
    "    X = np.array(X)\n",
    "    X_max = np.max(X,axis=0)\n",
    "    X_min = np.min(X,axis=0)\n",
    "    X_normalized = (X-X_min) / (X_max-X_min)\n",
    "    ones = np.ones(X_normalized.shape[0])\n",
    "    return np.column_stack((ones,X_normalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self,X_train,y_train,LAMBDA):\n",
    "        W = np.linalg.inv(X_train.T.dot(X_train) + LAMBDA*np.eye(X_train.shape[1])).dot(X_train.T.dot(y_train))\n",
    "        return W\n",
    "    def dataLoader(X_train,y_train,batch_size=16):\n",
    "        idx = np.arange(X_train.shape[0])\n",
    "        np.random.shuffle(idx)\n",
    "        X_train,y_train = X_train[idx],y_train[idx]\n",
    "        for i in range(0,X_train.shape[0],batch_size):\n",
    "            start,end = i,min(X_train.shape[0],i+batch_size)\n",
    "            yield X_train[start:end],y_train[start:end]\n",
    "\n",
    "    def fit_gradient(self,X_train,y_train,LAMBDA,batch_size,lr,epoch=10):\n",
    "        W = np.random.randn(X_train.shape[1])\n",
    "        last_loss = 10e+8\n",
    "        for _ in range(epoch):\n",
    "            for x,y in dataLoader(X_train,y_train,batch_size):\n",
    "                W -= lr *( X_train.T.dot(X_train.dot(W)-y_train) + LAMBDA * W)\n",
    "            new_loss = self.computeRSS(self.predict(W,X_train),y_train)\n",
    "            if np.abs(new_loss-last_loss)<=1e-5:\n",
    "                break\n",
    "            last_loss = new_loss\n",
    "            if _%100==0:\n",
    "                print(last_loss)\n",
    "        return W\n",
    "    \n",
    "    \n",
    "    def predict(self,W,X_new):\n",
    "        return np.array(X_new).dot(W)\n",
    "\n",
    "    def computeRSS(self,Y_new,Y_pred):\n",
    "        return np.mean((Y_new-Y_pred)**2)\n",
    "\n",
    "    def getTheBestLAMBDA(self,X_train,y_train):\n",
    "\n",
    "        def crossValidation(num_folds,LAMBDA):\n",
    "            row_ids = np.arange(X_train.shape[0])\n",
    "            valid_ids = np.split(row_ids[:len(row_ids)-len(row_ids) % num_folds],num_folds)\n",
    "            valid_ids[-1] = np.append(valid_ids[-1],row_ids[len(row_ids)-len(row_ids) % num_folds:])\n",
    "            train_ids = [[k for k in row_ids if k not in valid_ids[i]] for i in range(num_folds)]\n",
    "            avg_RSS = 0\n",
    "            for i in range(num_folds):\n",
    "                W = self.fit(X_train[train_ids[i]],y_train[train_ids[i]],LAMBDA)\n",
    "                y_pred = self.predict(W,X_train[valid_ids[i]])\n",
    "                avg_RSS+=self.computeRSS(y_train[valid_ids[i]],y_pred)\n",
    "                return avg_RSS / num_folds\n",
    "\n",
    "        def rangeScan(best_LAMBDA,min_RSS,LAMBDA_values):\n",
    "            for current_LAMBDA in LAMBDA_values:\n",
    "                avg_RSS = crossValidation(num_folds=2,LAMBDA=current_LAMBDA)\n",
    "                if avg_RSS < min_RSS:\n",
    "                    best_LAMBDA = current_LAMBDA\n",
    "                    min_RSS = avg_RSS\n",
    "            return best_LAMBDA,min_RSS\n",
    "\n",
    "        best_LAMBDA, min_RSS = rangeScan(best_LAMBDA=0,min_RSS=1000**2,LAMBDA_values=range(50))\n",
    "\n",
    "        LAMBDA_values = np.arange(max(0,(best_LAMBDA-1)*1000,(best_LAMBDA+1)*1000,1))*1.0/1000\n",
    "        best_LAMBDA,min_RSS = rangeScan(best_LAMBDA=best_LAMBDA,min_RSS=min_RSS,LAMBDA_values=LAMBDA_values)\n",
    "        \n",
    "        return best_LAMBDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = get_data('Data/DeathRate.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize_and_add_ones(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = X[:50],y[:50]\n",
    "X_test,y_test = X[50:],y[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = RidgeRegression()\n",
    "best_LAMBDA = ridge_reg.getTheBestLAMBDA(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_LAMBDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_learned = ridge_reg.fit(X_train,y_train,best_LAMBDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridge_reg.predict(W_learned,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ridge_reg.computeRSS(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374263.17878767184\n",
      "1367.2416055789502\n",
      "1013.8742222765867\n",
      "884.7089142046051\n",
      "830.9890875737989\n",
      "805.8313660520763\n",
      "792.729866806516\n",
      "785.25145187456\n",
      "780.6241370155641\n",
      "777.5445870599875\n"
     ]
    }
   ],
   "source": [
    "W_gradient = ridge_reg.fit_gradient(X_train,y_train,best_LAMBDA,batch_size=10,lr=0.01,epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_grad = ridge_reg.computeRSS(ridge_reg.predict(W_gradient,X_test),y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss with formula: 1416.56\n",
      "Loss with gradient: 0.55\n"
     ]
    }
   ],
   "source": [
    "print(f'Loss with formula: {loss:.2f}')\n",
    "print(f'Loss with gradient: {loss_grad:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov  4 2022, 16:35:55) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5581cd8f8e7f555d1c7b7d5c73b743c62e9c35962a29bf47b3ccdfb22fa58433"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
